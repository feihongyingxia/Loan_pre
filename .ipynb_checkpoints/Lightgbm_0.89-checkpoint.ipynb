{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48872b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import re\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ca5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./train_dataset/train_public.csv')\n",
    "test_data = pd.read_csv('./test_public.csv')\n",
    "sub=pd.read_csv(\"./submit/test1.csv\")\n",
    "sub=sub.rename(columns={'id': 'loan_id'})\n",
    "sub.loc[sub['isDefault']<0.5,'isDefault'] = 0\n",
    "nw_sub=sub[(sub['isDefault']==0)]\n",
    "nw_test_data=test_data.merge(nw_sub,on='loan_id',how='inner')\n",
    "nw_train_data = pd.concat([train_data,nw_test_data]).reset_index(drop=True)\n",
    "nw_train_data.to_csv(\"./train_dataset/nw_train_public.csv\",index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470429dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./train_dataset/nw_train_public.csv')\n",
    "submit_example = pd.read_csv('./submit_example.csv')\n",
    "test_public = pd.read_csv('./test_public.csv')\n",
    "train_internet = pd.read_csv('./train_dataset/train_internet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d3489d",
   "metadata": {},
   "source": [
    "## 模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc71410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_, test_, y_, folds_):\n",
    "    oof_preds = np.zeros(data_.shape[0])\n",
    "    sub_preds = np.zeros(test_.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = [f for f in data_.columns if f not in ['loan_id', 'user_id', 'isDefault'] ]\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds_.split(data_)):\n",
    "        trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]\n",
    "        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]\n",
    "        clf = LGBMClassifier(\n",
    "            n_estimators=4000,\n",
    "            learning_rate=0.08,\n",
    "            num_leaves=2**5,\n",
    "            colsample_bytree=.65,\n",
    "            subsample=.9,\n",
    "            max_depth=5,\n",
    "#             max_bin=250,\n",
    "            reg_alpha=.3,\n",
    "            reg_lambda=.3,\n",
    "            min_split_gain=.01,\n",
    "            min_child_weight=2,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "        \n",
    "        clf.fit(trn_x, trn_y, \n",
    "                eval_set= [(trn_x, trn_y), (val_x, val_y)], \n",
    "                eval_metric='auc', verbose=100, early_stopping_rounds=50  #30\n",
    "               )\n",
    "\n",
    "        oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_[feats], num_iteration=clf.best_iteration_)[:, 1] / folds_.n_splits\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n",
    "        del clf, trn_x, trn_y, val_x, val_y\n",
    "        gc.collect()\n",
    "        \n",
    "    print('Full AUC score %.6f' % roc_auc_score(y_, oof_preds)) \n",
    "    \n",
    "    test_['isDefault'] = sub_preds\n",
    "\n",
    "    return oof_preds, test_[['loan_id', 'isDefault']], feature_importance_df\n",
    "    \n",
    "def display_importances(feature_importance_df_):\n",
    "    # Plot feature importances\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "        by=\"importance\", ascending=False)[:50].index\n",
    "    \n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    \n",
    "    plt.figure(figsize=(8,10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", \n",
    "                data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d4fa4",
   "metadata": {},
   "source": [
    "## 特征工程 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f296da",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_year_dict = {\n",
    "    '< 1 year': 0,\n",
    "    '1 year': 1,\n",
    "    '2 years': 2,\n",
    "    '3 years': 3,\n",
    "    '4 years': 4,\n",
    "    '5 years': 5,\n",
    "    '6 years': 6,\n",
    "    '7 years': 7,\n",
    "    '8 years': 8,\n",
    "    '9 years': 9,\n",
    "    '10+ years': 10,\n",
    "}\n",
    "\n",
    "train_data['work_year'] = train_data['work_year'].map(work_year_dict)\n",
    "test_public['work_year'] = test_public['work_year'].map(work_year_dict)\n",
    "train_data['work_year'] = train_data['work_year'].fillna(-1)\n",
    "test_public['work_year'] = test_public['work_year'].fillna(-1)\n",
    "train_internet['work_year'] = train_internet['work_year'].map(work_year_dict)\n",
    "train_internet['work_year'] = train_internet['work_year'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e70a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {\n",
    "    'A': 1,\n",
    "    'B': 2,\n",
    "    'C': 3,\n",
    "    'D': 4,\n",
    "    'E': 5,\n",
    "    'F': 6,\n",
    "    'G': 7,\n",
    "}\n",
    "\n",
    "train_data['class'] = train_data['class'].map(class_dict)\n",
    "test_public['class'] = test_public['class'].map(class_dict)\n",
    "train_internet['class'] = train_internet['class'].map(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f618a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['issue_date'] = pd.to_datetime(train_data['issue_date'])\n",
    "test_public['issue_date'] = pd.to_datetime(test_public['issue_date'])\n",
    "train_internet['issue_date'] = pd.to_datetime(train_internet['issue_date'])\n",
    "\n",
    "train_data['issue_date_month'] = train_data['issue_date'].dt.month\n",
    "test_public['issue_date_month'] = train_data['issue_date'].dt.month\n",
    "train_internet['issue_date_month'] = train_internet['issue_date'].dt.month\n",
    "\n",
    "train_data['issue_date_dayofweek'] = train_data['issue_date'].dt.dayofweek\n",
    "test_public['issue_date_dayofweek'] = train_data['issue_date'].dt.dayofweek\n",
    "train_internet['issue_date_dayofweek'] = train_internet['issue_date'].dt.dayofweek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa2c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [train_data, test_public, train_internet]: \n",
    "    data['earlies_credit_mon'] = pd.to_datetime(data['earlies_credit_mon'],format='%Y-%m-%d',errors='coerce')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c89919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['earlies_credit_mon'] = pd.to_datetime(train_data['earlies_credit_mon'])\n",
    "train_data['earlies_credit_Mon'] = train_data['earlies_credit_mon'].dt.month\n",
    "train_data['earlies_credit_Year'] = train_data['earlies_credit_mon'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd83a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_public['earlies_credit_mon'] = pd.to_datetime(test_public['earlies_credit_mon'])\n",
    "test_public['earlies_credit_Mon'] = test_public['earlies_credit_mon'].dt.month\n",
    "test_public['earlies_credit_Year'] = test_public['earlies_credit_mon'].dt.year\n",
    "\n",
    "train_internet['earlies_credit_mon'] = pd.to_datetime(train_internet['earlies_credit_mon'])\n",
    "train_internet['earlies_credit_Mon'] = train_internet['earlies_credit_mon'].dt.month\n",
    "train_internet['earlies_credit_Year'] = train_internet['earlies_credit_mon'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e31e67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = ['issue_date', 'earlies_credit_mon', 'issue_date_month', 'earlies_credit_Mon','earlies_credit_Year']\n",
    "train_data = train_data.drop(col_to_drop, axis=1)\n",
    "test_public = test_public.drop(col_to_drop, axis=1)\n",
    "train_internet = train_internet.drop(col_to_drop, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ac53bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = ['employer_type', 'industry']\n",
    "for col in cat_cols:\n",
    "    lbl = LabelEncoder().fit(train_data[col])\n",
    "    train_data[col] = lbl.transform(train_data[col])\n",
    "    test_public[col] = lbl.transform(test_public[col])\n",
    "    train_internet[col] = lbl.transform(train_internet[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f0d6b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_cols = set(train_data.columns)\n",
    "same_col = list(tr_cols.intersection(set(train_internet.columns)))\n",
    "train_inteSame = train_internet[same_col].copy()\n",
    "\n",
    "Inte_add_cos = list(tr_cols.difference(set(same_col)))\n",
    "for col in Inte_add_cos:\n",
    "    train_inteSame[col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa77be43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's auc: 0.932699\ttraining's binary_logloss: 0.231848\tvalid_1's auc: 0.907154\tvalid_1's binary_logloss: 0.263071\n",
      "Fold  1 AUC : 0.907154\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959236\ttraining's binary_logloss: 0.192394\tvalid_1's auc: 0.903303\tvalid_1's binary_logloss: 0.24621\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's auc: 0.956245\ttraining's binary_logloss: 0.196049\tvalid_1's auc: 0.903995\tvalid_1's binary_logloss: 0.245435\n",
      "Fold  2 AUC : 0.903995\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959892\ttraining's binary_logloss: 0.192264\tvalid_1's auc: 0.896896\tvalid_1's binary_logloss: 0.237929\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's auc: 0.948996\ttraining's binary_logloss: 0.20639\tvalid_1's auc: 0.901558\tvalid_1's binary_logloss: 0.234311\n",
      "Fold  3 AUC : 0.901558\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.956623\ttraining's binary_logloss: 0.194889\tvalid_1's auc: 0.916565\tvalid_1's binary_logloss: 0.237686\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's auc: 0.944174\ttraining's binary_logloss: 0.210797\tvalid_1's auc: 0.918447\tvalid_1's binary_logloss: 0.236416\n",
      "Fold  4 AUC : 0.918447\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958223\ttraining's binary_logloss: 0.193102\tvalid_1's auc: 0.88754\tvalid_1's binary_logloss: 0.25302\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's auc: 0.941974\ttraining's binary_logloss: 0.215024\tvalid_1's auc: 0.894429\tvalid_1's binary_logloss: 0.246937\n",
      "Fold  5 AUC : 0.894429\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's auc: 0.937516\ttraining's binary_logloss: 0.220863\tvalid_1's auc: 0.887779\tvalid_1's binary_logloss: 0.26481\n",
      "Fold  6 AUC : 0.887779\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's auc: 0.935294\ttraining's binary_logloss: 0.225352\tvalid_1's auc: 0.908813\tvalid_1's binary_logloss: 0.255074\n",
      "Fold  7 AUC : 0.908813\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959967\ttraining's binary_logloss: 0.191059\tvalid_1's auc: 0.899278\tvalid_1's binary_logloss: 0.240643\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's auc: 0.947712\ttraining's binary_logloss: 0.207094\tvalid_1's auc: 0.900101\tvalid_1's binary_logloss: 0.239314\n",
      "Fold  8 AUC : 0.900101\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958324\ttraining's binary_logloss: 0.192403\tvalid_1's auc: 0.888751\tvalid_1's binary_logloss: 0.265511\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's auc: 0.94436\ttraining's binary_logloss: 0.211661\tvalid_1's auc: 0.892243\tvalid_1's binary_logloss: 0.262529\n",
      "Fold  9 AUC : 0.892243\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's auc: 0.936282\ttraining's binary_logloss: 0.225502\tvalid_1's auc: 0.903958\tvalid_1's binary_logloss: 0.241651\n",
      "Fold 10 AUC : 0.903958\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958494\ttraining's binary_logloss: 0.191639\tvalid_1's auc: 0.914886\tvalid_1's binary_logloss: 0.257102\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's auc: 0.946144\ttraining's binary_logloss: 0.207517\tvalid_1's auc: 0.91617\tvalid_1's binary_logloss: 0.254594\n",
      "Fold 11 AUC : 0.916170\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.95795\ttraining's binary_logloss: 0.191618\tvalid_1's auc: 0.903682\tvalid_1's binary_logloss: 0.263703\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's auc: 0.94722\ttraining's binary_logloss: 0.206111\tvalid_1's auc: 0.904969\tvalid_1's binary_logloss: 0.262099\n",
      "Fold 12 AUC : 0.904969\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's auc: 0.926165\ttraining's binary_logloss: 0.245286\tvalid_1's auc: 0.91611\tvalid_1's binary_logloss: 0.247522\n",
      "Fold 13 AUC : 0.916110\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958699\ttraining's binary_logloss: 0.192221\tvalid_1's auc: 0.914944\tvalid_1's binary_logloss: 0.232607\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's auc: 0.943236\ttraining's binary_logloss: 0.212941\tvalid_1's auc: 0.916765\tvalid_1's binary_logloss: 0.231608\n",
      "Fold 14 AUC : 0.916765\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.956391\ttraining's binary_logloss: 0.196304\tvalid_1's auc: 0.905528\tvalid_1's binary_logloss: 0.237929\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's auc: 0.941004\ttraining's binary_logloss: 0.216248\tvalid_1's auc: 0.907395\tvalid_1's binary_logloss: 0.237331\n",
      "Fold 15 AUC : 0.907395\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959396\ttraining's binary_logloss: 0.191776\tvalid_1's auc: 0.912463\tvalid_1's binary_logloss: 0.240145\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's auc: 0.950872\ttraining's binary_logloss: 0.202563\tvalid_1's auc: 0.914035\tvalid_1's binary_logloss: 0.239074\n",
      "Fold 16 AUC : 0.914035\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's auc: 0.938094\ttraining's binary_logloss: 0.220548\tvalid_1's auc: 0.913993\tvalid_1's binary_logloss: 0.249235\n",
      "Fold 17 AUC : 0.913993\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.957734\ttraining's binary_logloss: 0.19446\tvalid_1's auc: 0.914093\tvalid_1's binary_logloss: 0.227672\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's auc: 0.967957\ttraining's binary_logloss: 0.18077\tvalid_1's auc: 0.915916\tvalid_1's binary_logloss: 0.225788\n",
      "Fold 18 AUC : 0.915916\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.935027\ttraining's binary_logloss: 0.227092\tvalid_1's auc: 0.901024\tvalid_1's binary_logloss: 0.250174\n",
      "Fold 19 AUC : 0.901024\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.960884\ttraining's binary_logloss: 0.189917\tvalid_1's auc: 0.894883\tvalid_1's binary_logloss: 0.250746\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's auc: 0.944139\ttraining's binary_logloss: 0.212433\tvalid_1's auc: 0.898703\tvalid_1's binary_logloss: 0.247934\n",
      "Fold 20 AUC : 0.898703\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959723\ttraining's binary_logloss: 0.190484\tvalid_1's auc: 0.902209\tvalid_1's binary_logloss: 0.261631\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's auc: 0.948744\ttraining's binary_logloss: 0.204406\tvalid_1's auc: 0.902248\tvalid_1's binary_logloss: 0.260668\n",
      "Fold 21 AUC : 0.902248\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.915009\ttraining's binary_logloss: 0.320961\tvalid_1's auc: 0.895544\tvalid_1's binary_logloss: 0.336017\n",
      "Fold 22 AUC : 0.895544\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's auc: 0.93249\ttraining's binary_logloss: 0.229416\tvalid_1's auc: 0.910801\tvalid_1's binary_logloss: 0.262901\n",
      "Fold 23 AUC : 0.910801\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's auc: 0.934505\ttraining's binary_logloss: 0.226811\tvalid_1's auc: 0.903779\tvalid_1's binary_logloss: 0.262642\n",
      "Fold 24 AUC : 0.903779\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.95967\ttraining's binary_logloss: 0.190778\tvalid_1's auc: 0.911425\tvalid_1's binary_logloss: 0.246386\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's auc: 0.96275\ttraining's binary_logloss: 0.186755\tvalid_1's auc: 0.912643\tvalid_1's binary_logloss: 0.245233\n",
      "Fold 25 AUC : 0.912643\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's auc: 0.939236\ttraining's binary_logloss: 0.21956\tvalid_1's auc: 0.909336\tvalid_1's binary_logloss: 0.24124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 26 AUC : 0.909336\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.957478\ttraining's binary_logloss: 0.193656\tvalid_1's auc: 0.90525\tvalid_1's binary_logloss: 0.246462\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's auc: 0.948039\ttraining's binary_logloss: 0.205673\tvalid_1's auc: 0.907257\tvalid_1's binary_logloss: 0.244428\n",
      "Fold 27 AUC : 0.907257\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.922794\ttraining's binary_logloss: 0.255253\tvalid_1's auc: 0.909107\tvalid_1's binary_logloss: 0.272856\n",
      "Fold 28 AUC : 0.909107\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959304\ttraining's binary_logloss: 0.189436\tvalid_1's auc: 0.893287\tvalid_1's binary_logloss: 0.274656\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's auc: 0.947351\ttraining's binary_logloss: 0.206087\tvalid_1's auc: 0.89366\tvalid_1's binary_logloss: 0.272352\n",
      "Fold 29 AUC : 0.893660\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's auc: 0.934685\ttraining's binary_logloss: 0.226362\tvalid_1's auc: 0.925213\tvalid_1's binary_logloss: 0.236092\n",
      "Fold 30 AUC : 0.925213\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's auc: 0.940733\ttraining's binary_logloss: 0.215539\tvalid_1's auc: 0.899776\tvalid_1's binary_logloss: 0.258547\n",
      "Fold 31 AUC : 0.899776\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959977\ttraining's binary_logloss: 0.190947\tvalid_1's auc: 0.90922\tvalid_1's binary_logloss: 0.241575\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's auc: 0.949233\ttraining's binary_logloss: 0.204937\tvalid_1's auc: 0.913043\tvalid_1's binary_logloss: 0.239149\n",
      "Fold 32 AUC : 0.913043\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.957987\ttraining's binary_logloss: 0.191577\tvalid_1's auc: 0.906828\tvalid_1's binary_logloss: 0.259451\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's auc: 0.943376\ttraining's binary_logloss: 0.211071\tvalid_1's auc: 0.908134\tvalid_1's binary_logloss: 0.2593\n",
      "Fold 33 AUC : 0.908134\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's auc: 0.938209\ttraining's binary_logloss: 0.221123\tvalid_1's auc: 0.890674\tvalid_1's binary_logloss: 0.268891\n",
      "Fold 34 AUC : 0.890674\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.94305\ttraining's binary_logloss: 0.214155\tvalid_1's auc: 0.879037\tvalid_1's binary_logloss: 0.279791\n",
      "Fold 35 AUC : 0.879037\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.956964\ttraining's binary_logloss: 0.194744\tvalid_1's auc: 0.904883\tvalid_1's binary_logloss: 0.243175\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's auc: 0.941356\ttraining's binary_logloss: 0.216363\tvalid_1's auc: 0.90557\tvalid_1's binary_logloss: 0.243267\n",
      "Fold 36 AUC : 0.905570\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959599\ttraining's binary_logloss: 0.19107\tvalid_1's auc: 0.8991\tvalid_1's binary_logloss: 0.255445\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's auc: 0.944343\ttraining's binary_logloss: 0.211409\tvalid_1's auc: 0.899475\tvalid_1's binary_logloss: 0.25379\n",
      "Fold 37 AUC : 0.899475\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.957345\ttraining's binary_logloss: 0.192955\tvalid_1's auc: 0.89805\tvalid_1's binary_logloss: 0.263832\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's auc: 0.947226\ttraining's binary_logloss: 0.205528\tvalid_1's auc: 0.899973\tvalid_1's binary_logloss: 0.261555\n",
      "Fold 38 AUC : 0.899973\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.95715\ttraining's binary_logloss: 0.195992\tvalid_1's auc: 0.910892\tvalid_1's binary_logloss: 0.230476\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's auc: 0.946017\ttraining's binary_logloss: 0.209842\tvalid_1's auc: 0.91363\tvalid_1's binary_logloss: 0.229062\n",
      "Fold 39 AUC : 0.913630\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.940549\ttraining's binary_logloss: 0.216206\tvalid_1's auc: 0.904287\tvalid_1's binary_logloss: 0.268114\n",
      "Fold 40 AUC : 0.904287\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958406\ttraining's binary_logloss: 0.192276\tvalid_1's auc: 0.903434\tvalid_1's binary_logloss: 0.250161\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's auc: 0.944735\ttraining's binary_logloss: 0.209109\tvalid_1's auc: 0.90502\tvalid_1's binary_logloss: 0.249057\n",
      "Fold 41 AUC : 0.905020\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's auc: 0.931898\ttraining's binary_logloss: 0.230693\tvalid_1's auc: 0.917765\tvalid_1's binary_logloss: 0.249947\n",
      "Fold 42 AUC : 0.917765\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.961422\ttraining's binary_logloss: 0.188396\tvalid_1's auc: 0.901679\tvalid_1's binary_logloss: 0.257382\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's auc: 0.958757\ttraining's binary_logloss: 0.192034\tvalid_1's auc: 0.902288\tvalid_1's binary_logloss: 0.257194\n",
      "Fold 43 AUC : 0.902288\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959338\ttraining's binary_logloss: 0.189891\tvalid_1's auc: 0.904842\tvalid_1's binary_logloss: 0.260534\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's auc: 0.969953\ttraining's binary_logloss: 0.175247\tvalid_1's auc: 0.906797\tvalid_1's binary_logloss: 0.259467\n",
      "Fold 44 AUC : 0.906797\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.912071\ttraining's binary_logloss: 0.324096\tvalid_1's auc: 0.92267\tvalid_1's binary_logloss: 0.314143\n",
      "Fold 45 AUC : 0.922670\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.929211\ttraining's binary_logloss: 0.238492\tvalid_1's auc: 0.905148\tvalid_1's binary_logloss: 0.244914\n",
      "Fold 46 AUC : 0.905148\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's auc: 0.921402\ttraining's binary_logloss: 0.275138\tvalid_1's auc: 0.915715\tvalid_1's binary_logloss: 0.279525\n",
      "Fold 47 AUC : 0.915715\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.957964\ttraining's binary_logloss: 0.193347\tvalid_1's auc: 0.912387\tvalid_1's binary_logloss: 0.232714\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's auc: 0.9467\ttraining's binary_logloss: 0.207641\tvalid_1's auc: 0.914798\tvalid_1's binary_logloss: 0.230178\n",
      "Fold 48 AUC : 0.914798\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's auc: 0.931154\ttraining's binary_logloss: 0.233551\tvalid_1's auc: 0.891879\tvalid_1's binary_logloss: 0.270346\n",
      "Fold 49 AUC : 0.891879\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's auc: 0.939533\ttraining's binary_logloss: 0.217275\tvalid_1's auc: 0.904118\tvalid_1's binary_logloss: 0.253052\n",
      "Fold 50 AUC : 0.904118\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.957535\ttraining's binary_logloss: 0.194853\tvalid_1's auc: 0.906015\tvalid_1's binary_logloss: 0.232603\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's auc: 0.953267\ttraining's binary_logloss: 0.200288\tvalid_1's auc: 0.906753\tvalid_1's binary_logloss: 0.231473\n",
      "Fold 51 AUC : 0.906753\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.961285\ttraining's binary_logloss: 0.190074\tvalid_1's auc: 0.899705\tvalid_1's binary_logloss: 0.239453\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's auc: 0.947545\ttraining's binary_logloss: 0.207785\tvalid_1's auc: 0.901489\tvalid_1's binary_logloss: 0.236616\n",
      "Fold 52 AUC : 0.901489\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's auc: 0.93354\ttraining's binary_logloss: 0.229032\tvalid_1's auc: 0.924395\tvalid_1's binary_logloss: 0.22125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 53 AUC : 0.924395\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.939052\ttraining's binary_logloss: 0.220046\tvalid_1's auc: 0.912768\tvalid_1's binary_logloss: 0.240905\n",
      "Fold 54 AUC : 0.912768\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958595\ttraining's binary_logloss: 0.192364\tvalid_1's auc: 0.918105\tvalid_1's binary_logloss: 0.238215\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's auc: 0.950408\ttraining's binary_logloss: 0.202844\tvalid_1's auc: 0.918702\tvalid_1's binary_logloss: 0.238175\n",
      "Fold 55 AUC : 0.918702\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.957699\ttraining's binary_logloss: 0.191312\tvalid_1's auc: 0.891\tvalid_1's binary_logloss: 0.289414\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's auc: 0.946661\ttraining's binary_logloss: 0.205426\tvalid_1's auc: 0.891433\tvalid_1's binary_logloss: 0.287804\n",
      "Fold 56 AUC : 0.891433\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.957899\ttraining's binary_logloss: 0.192805\tvalid_1's auc: 0.895601\tvalid_1's binary_logloss: 0.248611\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's auc: 0.94307\ttraining's binary_logloss: 0.213211\tvalid_1's auc: 0.896721\tvalid_1's binary_logloss: 0.24714\n",
      "Fold 57 AUC : 0.896721\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.939419\ttraining's binary_logloss: 0.220128\tvalid_1's auc: 0.914967\tvalid_1's binary_logloss: 0.230118\n",
      "Fold 58 AUC : 0.914967\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's auc: 0.926489\ttraining's binary_logloss: 0.245971\tvalid_1's auc: 0.905608\tvalid_1's binary_logloss: 0.259317\n",
      "Fold 59 AUC : 0.905608\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.962202\ttraining's binary_logloss: 0.186171\tvalid_1's auc: 0.894385\tvalid_1's binary_logloss: 0.262587\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's auc: 0.950369\ttraining's binary_logloss: 0.202066\tvalid_1's auc: 0.897032\tvalid_1's binary_logloss: 0.260103\n",
      "Fold 60 AUC : 0.897032\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.941479\ttraining's binary_logloss: 0.215205\tvalid_1's auc: 0.882507\tvalid_1's binary_logloss: 0.280337\n",
      "Fold 61 AUC : 0.882507\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.957396\ttraining's binary_logloss: 0.193708\tvalid_1's auc: 0.896936\tvalid_1's binary_logloss: 0.254355\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's auc: 0.949437\ttraining's binary_logloss: 0.203395\tvalid_1's auc: 0.899432\tvalid_1's binary_logloss: 0.252535\n",
      "Fold 62 AUC : 0.899432\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.956898\ttraining's binary_logloss: 0.192623\tvalid_1's auc: 0.903113\tvalid_1's binary_logloss: 0.264593\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's auc: 0.942781\ttraining's binary_logloss: 0.212517\tvalid_1's auc: 0.905565\tvalid_1's binary_logloss: 0.264109\n",
      "Fold 63 AUC : 0.905565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's auc: 0.920846\ttraining's binary_logloss: 0.268243\tvalid_1's auc: 0.903051\tvalid_1's binary_logloss: 0.27811\n",
      "Fold 64 AUC : 0.903051\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.9585\ttraining's binary_logloss: 0.192457\tvalid_1's auc: 0.914759\tvalid_1's binary_logloss: 0.24654\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's auc: 0.964661\ttraining's binary_logloss: 0.184104\tvalid_1's auc: 0.916141\tvalid_1's binary_logloss: 0.245208\n",
      "Fold 65 AUC : 0.916141\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.96013\ttraining's binary_logloss: 0.189696\tvalid_1's auc: 0.901928\tvalid_1's binary_logloss: 0.268935\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's auc: 0.947116\ttraining's binary_logloss: 0.206432\tvalid_1's auc: 0.902633\tvalid_1's binary_logloss: 0.266787\n",
      "Fold 66 AUC : 0.902633\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959413\ttraining's binary_logloss: 0.191331\tvalid_1's auc: 0.904323\tvalid_1's binary_logloss: 0.251423\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's auc: 0.94959\ttraining's binary_logloss: 0.204087\tvalid_1's auc: 0.907013\tvalid_1's binary_logloss: 0.249057\n",
      "Fold 67 AUC : 0.907013\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.956745\ttraining's binary_logloss: 0.193956\tvalid_1's auc: 0.91199\tvalid_1's binary_logloss: 0.244706\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's auc: 0.945357\ttraining's binary_logloss: 0.208965\tvalid_1's auc: 0.914471\tvalid_1's binary_logloss: 0.242137\n",
      "Fold 68 AUC : 0.914471\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958234\ttraining's binary_logloss: 0.191504\tvalid_1's auc: 0.906625\tvalid_1's binary_logloss: 0.257148\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.947566\ttraining's binary_logloss: 0.204756\tvalid_1's auc: 0.908819\tvalid_1's binary_logloss: 0.255854\n",
      "Fold 69 AUC : 0.908819\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.925299\ttraining's binary_logloss: 0.25143\tvalid_1's auc: 0.89556\tvalid_1's binary_logloss: 0.273715\n",
      "Fold 70 AUC : 0.895560\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.956835\ttraining's binary_logloss: 0.194494\tvalid_1's auc: 0.910676\tvalid_1's binary_logloss: 0.246255\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's auc: 0.949507\ttraining's binary_logloss: 0.203514\tvalid_1's auc: 0.911398\tvalid_1's binary_logloss: 0.24592\n",
      "Fold 71 AUC : 0.911398\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.912808\ttraining's binary_logloss: 0.322656\tvalid_1's auc: 0.910954\tvalid_1's binary_logloss: 0.324766\n",
      "Fold 72 AUC : 0.910954\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959146\ttraining's binary_logloss: 0.191637\tvalid_1's auc: 0.885417\tvalid_1's binary_logloss: 0.256476\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's auc: 0.952494\ttraining's binary_logloss: 0.200665\tvalid_1's auc: 0.884956\tvalid_1's binary_logloss: 0.255675\n",
      "Fold 73 AUC : 0.884956\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's auc: 0.914469\ttraining's binary_logloss: 0.313513\tvalid_1's auc: 0.90113\tvalid_1's binary_logloss: 0.328808\n",
      "Fold 74 AUC : 0.901130\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959563\ttraining's binary_logloss: 0.190054\tvalid_1's auc: 0.886707\tvalid_1's binary_logloss: 0.270926\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's auc: 0.948724\ttraining's binary_logloss: 0.204525\tvalid_1's auc: 0.887123\tvalid_1's binary_logloss: 0.26901\n",
      "Fold 75 AUC : 0.887123\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.939744\ttraining's binary_logloss: 0.219401\tvalid_1's auc: 0.900809\tvalid_1's binary_logloss: 0.24415\n",
      "Fold 76 AUC : 0.900809\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.956377\ttraining's binary_logloss: 0.195324\tvalid_1's auc: 0.910068\tvalid_1's binary_logloss: 0.242012\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's auc: 0.943253\ttraining's binary_logloss: 0.212208\tvalid_1's auc: 0.91177\tvalid_1's binary_logloss: 0.240399\n",
      "Fold 77 AUC : 0.911770\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.957095\ttraining's binary_logloss: 0.195108\tvalid_1's auc: 0.904554\tvalid_1's binary_logloss: 0.244351\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's auc: 0.941211\ttraining's binary_logloss: 0.215602\tvalid_1's auc: 0.908245\tvalid_1's binary_logloss: 0.240576\n",
      "Fold 78 AUC : 0.908245\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.95878\ttraining's binary_logloss: 0.192838\tvalid_1's auc: 0.897753\tvalid_1's binary_logloss: 0.245249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's auc: 0.943696\ttraining's binary_logloss: 0.21337\tvalid_1's auc: 0.900212\tvalid_1's binary_logloss: 0.242947\n",
      "Fold 79 AUC : 0.900212\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.960612\ttraining's binary_logloss: 0.189621\tvalid_1's auc: 0.902573\tvalid_1's binary_logloss: 0.25528\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's auc: 0.944296\ttraining's binary_logloss: 0.211016\tvalid_1's auc: 0.905762\tvalid_1's binary_logloss: 0.254198\n",
      "Fold 80 AUC : 0.905762\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.9587\ttraining's binary_logloss: 0.191189\tvalid_1's auc: 0.890596\tvalid_1's binary_logloss: 0.263984\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's auc: 0.946168\ttraining's binary_logloss: 0.207852\tvalid_1's auc: 0.893278\tvalid_1's binary_logloss: 0.260861\n",
      "Fold 81 AUC : 0.893278\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.939766\ttraining's binary_logloss: 0.219131\tvalid_1's auc: 0.90867\tvalid_1's binary_logloss: 0.236752\n",
      "Fold 82 AUC : 0.908670\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.95779\ttraining's binary_logloss: 0.192988\tvalid_1's auc: 0.909272\tvalid_1's binary_logloss: 0.252541\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's auc: 0.954396\ttraining's binary_logloss: 0.197253\tvalid_1's auc: 0.909939\tvalid_1's binary_logloss: 0.252277\n",
      "Fold 83 AUC : 0.909939\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.908068\ttraining's binary_logloss: 0.348926\tvalid_1's auc: 0.909875\tvalid_1's binary_logloss: 0.352414\n",
      "Fold 84 AUC : 0.909875\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.960486\ttraining's binary_logloss: 0.189184\tvalid_1's auc: 0.899954\tvalid_1's binary_logloss: 0.26126\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's auc: 0.944983\ttraining's binary_logloss: 0.209133\tvalid_1's auc: 0.901951\tvalid_1's binary_logloss: 0.258363\n",
      "Fold 85 AUC : 0.901951\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.960713\ttraining's binary_logloss: 0.188204\tvalid_1's auc: 0.908942\tvalid_1's binary_logloss: 0.269556\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's auc: 0.946786\ttraining's binary_logloss: 0.205575\tvalid_1's auc: 0.909501\tvalid_1's binary_logloss: 0.269582\n",
      "Fold 86 AUC : 0.909501\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958724\ttraining's binary_logloss: 0.192866\tvalid_1's auc: 0.906257\tvalid_1's binary_logloss: 0.24423\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's auc: 0.945297\ttraining's binary_logloss: 0.210156\tvalid_1's auc: 0.908825\tvalid_1's binary_logloss: 0.242014\n",
      "Fold 87 AUC : 0.908825\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958125\ttraining's binary_logloss: 0.193564\tvalid_1's auc: 0.910405\tvalid_1's binary_logloss: 0.244817\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's auc: 0.943915\ttraining's binary_logloss: 0.211376\tvalid_1's auc: 0.911187\tvalid_1's binary_logloss: 0.243604\n",
      "Fold 88 AUC : 0.911187\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's auc: 0.917429\ttraining's binary_logloss: 0.287285\tvalid_1's auc: 0.921529\tvalid_1's binary_logloss: 0.279548\n",
      "Fold 89 AUC : 0.921529\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's auc: 0.920577\ttraining's binary_logloss: 0.275553\tvalid_1's auc: 0.902552\tvalid_1's binary_logloss: 0.278367\n",
      "Fold 90 AUC : 0.902552\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958418\ttraining's binary_logloss: 0.192629\tvalid_1's auc: 0.909931\tvalid_1's binary_logloss: 0.245064\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's auc: 0.94508\ttraining's binary_logloss: 0.209949\tvalid_1's auc: 0.913445\tvalid_1's binary_logloss: 0.24302\n",
      "Fold 91 AUC : 0.913445\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.959459\ttraining's binary_logloss: 0.191133\tvalid_1's auc: 0.912918\tvalid_1's binary_logloss: 0.249948\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttraining's auc: 0.959722\ttraining's binary_logloss: 0.190827\tvalid_1's auc: 0.912929\tvalid_1's binary_logloss: 0.249848\n",
      "Fold 92 AUC : 0.912929\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.956823\ttraining's binary_logloss: 0.194994\tvalid_1's auc: 0.914063\tvalid_1's binary_logloss: 0.232429\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's auc: 0.940832\ttraining's binary_logloss: 0.216817\tvalid_1's auc: 0.917013\tvalid_1's binary_logloss: 0.232439\n",
      "Fold 93 AUC : 0.917013\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958721\ttraining's binary_logloss: 0.190789\tvalid_1's auc: 0.899105\tvalid_1's binary_logloss: 0.264566\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's auc: 0.946469\ttraining's binary_logloss: 0.206205\tvalid_1's auc: 0.898939\tvalid_1's binary_logloss: 0.263312\n",
      "Fold 94 AUC : 0.898939\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958616\ttraining's binary_logloss: 0.192242\tvalid_1's auc: 0.902757\tvalid_1's binary_logloss: 0.242269\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's auc: 0.950282\ttraining's binary_logloss: 0.203271\tvalid_1's auc: 0.903576\tvalid_1's binary_logloss: 0.24129\n",
      "Fold 95 AUC : 0.903576\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.960365\ttraining's binary_logloss: 0.189177\tvalid_1's auc: 0.899009\tvalid_1's binary_logloss: 0.273701\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's auc: 0.950569\ttraining's binary_logloss: 0.201625\tvalid_1's auc: 0.901104\tvalid_1's binary_logloss: 0.272288\n",
      "Fold 96 AUC : 0.901104\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.940551\ttraining's binary_logloss: 0.216053\tvalid_1's auc: 0.895877\tvalid_1's binary_logloss: 0.260012\n",
      "Fold 97 AUC : 0.895877\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's auc: 0.937092\ttraining's binary_logloss: 0.221878\tvalid_1's auc: 0.883509\tvalid_1's binary_logloss: 0.284624\n",
      "Fold 98 AUC : 0.883509\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's auc: 0.936778\ttraining's binary_logloss: 0.223805\tvalid_1's auc: 0.886194\tvalid_1's binary_logloss: 0.266291\n",
      "Fold 99 AUC : 0.886194\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.958813\ttraining's binary_logloss: 0.19243\tvalid_1's auc: 0.91715\tvalid_1's binary_logloss: 0.239941\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's auc: 0.945468\ttraining's binary_logloss: 0.209673\tvalid_1's auc: 0.919032\tvalid_1's binary_logloss: 0.239115\n",
      "Fold 100 AUC : 0.919032\n",
      "Full AUC score 0.898014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7303194503494158"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_data['isDefault']\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=546789)\n",
    "oof_preds, IntePre, importances = train_model(train_data, train_inteSame, y, folds)\n",
    "\n",
    "IntePre['isDef'] = train_internet['is_default']\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(IntePre['isDef'],IntePre.isDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eca66cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "InteId = IntePre.loc[IntePre.isDefault<0.5, 'loan_id'].tolist()\n",
    "\n",
    "train_data['dataSourse'] = 1\n",
    "test_public['dataSourse'] = 1\n",
    "train_inteSame['dataSourse'] = 0\n",
    "train_inteSame['isDefault'] = train_internet['is_default']\n",
    "use_te = train_inteSame[train_inteSame.loan_id.isin( InteId )].copy()\n",
    "data = pd.concat([ train_data,test_public,use_te]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cf951b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Distribution of Default values IntePre\")\n",
    "sns.distplot(IntePre['isDefault'],color=\"black\", kde=True,bins=120, label='train_data')\n",
    "# sns.distplot(train_inte[col],color=\"red\", kde=True,bins=120, label='train_inte')\n",
    "plt.legend();plt.show()\n",
    "train = data[data['isDefault'].notna()]\n",
    "test  = data[data['isDefault'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec9b7c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's auc: 0.989056\ttraining's binary_logloss: 0.0431382\tvalid_1's auc: 0.986196\tvalid_1's binary_logloss: 0.0447814\n",
      "Fold  1 AUC : 0.986196\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991933\ttraining's binary_logloss: 0.0372358\tvalid_1's auc: 0.984838\tvalid_1's binary_logloss: 0.0453325\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's auc: 0.991123\ttraining's binary_logloss: 0.0383757\tvalid_1's auc: 0.984968\tvalid_1's binary_logloss: 0.0450597\n",
      "Fold  2 AUC : 0.984968\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992143\ttraining's binary_logloss: 0.0365557\tvalid_1's auc: 0.985111\tvalid_1's binary_logloss: 0.0491915\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's auc: 0.990792\ttraining's binary_logloss: 0.038438\tvalid_1's auc: 0.985387\tvalid_1's binary_logloss: 0.0488893\n",
      "Fold  3 AUC : 0.985387\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.989266\ttraining's binary_logloss: 0.0426538\tvalid_1's auc: 0.98358\tvalid_1's binary_logloss: 0.0475583\n",
      "Fold  4 AUC : 0.983580\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.99196\ttraining's binary_logloss: 0.037321\tvalid_1's auc: 0.983003\tvalid_1's binary_logloss: 0.0448865\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's auc: 0.990845\ttraining's binary_logloss: 0.0389206\tvalid_1's auc: 0.983404\tvalid_1's binary_logloss: 0.0446607\n",
      "Fold  5 AUC : 0.983404\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.988557\ttraining's binary_logloss: 0.0449573\tvalid_1's auc: 0.98749\tvalid_1's binary_logloss: 0.0522137\n",
      "Fold  6 AUC : 0.987490\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991865\ttraining's binary_logloss: 0.037428\tvalid_1's auc: 0.983851\tvalid_1's binary_logloss: 0.0452838\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's auc: 0.990608\ttraining's binary_logloss: 0.039239\tvalid_1's auc: 0.984202\tvalid_1's binary_logloss: 0.0447999\n",
      "Fold  7 AUC : 0.984202\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's auc: 0.989271\ttraining's binary_logloss: 0.0425819\tvalid_1's auc: 0.985299\tvalid_1's binary_logloss: 0.04466\n",
      "Fold  8 AUC : 0.985299\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's auc: 0.989115\ttraining's binary_logloss: 0.0428588\tvalid_1's auc: 0.983329\tvalid_1's binary_logloss: 0.049601\n",
      "Fold  9 AUC : 0.983329\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's auc: 0.989328\ttraining's binary_logloss: 0.04224\tvalid_1's auc: 0.985547\tvalid_1's binary_logloss: 0.0476352\n",
      "Fold 10 AUC : 0.985547\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.988913\ttraining's binary_logloss: 0.0448292\tvalid_1's auc: 0.983808\tvalid_1's binary_logloss: 0.0487453\n",
      "Fold 11 AUC : 0.983808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.989494\ttraining's binary_logloss: 0.041378\tvalid_1's auc: 0.984842\tvalid_1's binary_logloss: 0.0455399\n",
      "Fold 12 AUC : 0.984842\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991939\ttraining's binary_logloss: 0.0370429\tvalid_1's auc: 0.982805\tvalid_1's binary_logloss: 0.0476909\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's auc: 0.990596\ttraining's binary_logloss: 0.0389359\tvalid_1's auc: 0.983051\tvalid_1's binary_logloss: 0.0474389\n",
      "Fold 13 AUC : 0.983051\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992095\ttraining's binary_logloss: 0.0368439\tvalid_1's auc: 0.98484\tvalid_1's binary_logloss: 0.0458949\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttraining's auc: 0.992327\ttraining's binary_logloss: 0.0365227\tvalid_1's auc: 0.984922\tvalid_1's binary_logloss: 0.0458234\n",
      "Fold 14 AUC : 0.984922\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.99183\ttraining's binary_logloss: 0.0373255\tvalid_1's auc: 0.985706\tvalid_1's binary_logloss: 0.0445774\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's auc: 0.990107\ttraining's binary_logloss: 0.0398444\tvalid_1's auc: 0.98584\tvalid_1's binary_logloss: 0.0447595\n",
      "Fold 15 AUC : 0.985840\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992001\ttraining's binary_logloss: 0.0374265\tvalid_1's auc: 0.98503\tvalid_1's binary_logloss: 0.0406281\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's auc: 0.990311\ttraining's binary_logloss: 0.0398971\tvalid_1's auc: 0.985485\tvalid_1's binary_logloss: 0.0403725\n",
      "Fold 16 AUC : 0.985485\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992103\ttraining's binary_logloss: 0.0367747\tvalid_1's auc: 0.984802\tvalid_1's binary_logloss: 0.0465866\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's auc: 0.990715\ttraining's binary_logloss: 0.0387351\tvalid_1's auc: 0.98506\tvalid_1's binary_logloss: 0.0462844\n",
      "Fold 17 AUC : 0.985060\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.99206\ttraining's binary_logloss: 0.0371809\tvalid_1's auc: 0.982777\tvalid_1's binary_logloss: 0.0448621\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's auc: 0.99116\ttraining's binary_logloss: 0.0384557\tvalid_1's auc: 0.982785\tvalid_1's binary_logloss: 0.0447579\n",
      "Fold 18 AUC : 0.982785\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991757\ttraining's binary_logloss: 0.0374414\tvalid_1's auc: 0.985463\tvalid_1's binary_logloss: 0.0441652\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's auc: 0.990317\ttraining's binary_logloss: 0.0396318\tvalid_1's auc: 0.985576\tvalid_1's binary_logloss: 0.044263\n",
      "Fold 19 AUC : 0.985576\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992118\ttraining's binary_logloss: 0.0369246\tvalid_1's auc: 0.982641\tvalid_1's binary_logloss: 0.0469256\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's auc: 0.991763\ttraining's binary_logloss: 0.0374224\tvalid_1's auc: 0.982665\tvalid_1's binary_logloss: 0.0468286\n",
      "Fold 20 AUC : 0.982665\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's auc: 0.98981\ttraining's binary_logloss: 0.0408745\tvalid_1's auc: 0.983493\tvalid_1's binary_logloss: 0.04681\n",
      "Fold 21 AUC : 0.983493\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991844\ttraining's binary_logloss: 0.03737\tvalid_1's auc: 0.983221\tvalid_1's binary_logloss: 0.0461622\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's auc: 0.989768\ttraining's binary_logloss: 0.0406873\tvalid_1's auc: 0.983744\tvalid_1's binary_logloss: 0.0459015\n",
      "Fold 22 AUC : 0.983744\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991966\ttraining's binary_logloss: 0.0374551\tvalid_1's auc: 0.986115\tvalid_1's binary_logloss: 0.0402584\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's auc: 0.990117\ttraining's binary_logloss: 0.0401797\tvalid_1's auc: 0.986537\tvalid_1's binary_logloss: 0.0401428\n",
      "Fold 23 AUC : 0.986537\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.988122\ttraining's binary_logloss: 0.0492623\tvalid_1's auc: 0.986481\tvalid_1's binary_logloss: 0.0516097\n",
      "Fold 24 AUC : 0.986481\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992182\ttraining's binary_logloss: 0.0367707\tvalid_1's auc: 0.983796\tvalid_1's binary_logloss: 0.0471106\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's auc: 0.990869\ttraining's binary_logloss: 0.0385971\tvalid_1's auc: 0.984017\tvalid_1's binary_logloss: 0.0469663\n",
      "Fold 25 AUC : 0.984017\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992169\ttraining's binary_logloss: 0.0368218\tvalid_1's auc: 0.984659\tvalid_1's binary_logloss: 0.0450178\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's auc: 0.990829\ttraining's binary_logloss: 0.0386995\tvalid_1's auc: 0.984667\tvalid_1's binary_logloss: 0.0449079\n",
      "Fold 26 AUC : 0.984667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992059\ttraining's binary_logloss: 0.0368183\tvalid_1's auc: 0.984958\tvalid_1's binary_logloss: 0.0463182\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's auc: 0.990244\ttraining's binary_logloss: 0.0394524\tvalid_1's auc: 0.985023\tvalid_1's binary_logloss: 0.046213\n",
      "Fold 27 AUC : 0.985023\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.989386\ttraining's binary_logloss: 0.0409734\tvalid_1's auc: 0.985472\tvalid_1's binary_logloss: 0.049845\n",
      "Fold 28 AUC : 0.985472\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's auc: 0.989587\ttraining's binary_logloss: 0.0425125\tvalid_1's auc: 0.981384\tvalid_1's binary_logloss: 0.0498827\n",
      "Fold 29 AUC : 0.981384\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's auc: 0.989357\ttraining's binary_logloss: 0.0419258\tvalid_1's auc: 0.984466\tvalid_1's binary_logloss: 0.0457557\n",
      "Fold 30 AUC : 0.984466\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992115\ttraining's binary_logloss: 0.03672\tvalid_1's auc: 0.981709\tvalid_1's binary_logloss: 0.05127\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's auc: 0.990633\ttraining's binary_logloss: 0.0387286\tvalid_1's auc: 0.981692\tvalid_1's binary_logloss: 0.0509592\n",
      "Fold 31 AUC : 0.981692\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991859\ttraining's binary_logloss: 0.0374184\tvalid_1's auc: 0.984717\tvalid_1's binary_logloss: 0.0430966\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's auc: 0.990901\ttraining's binary_logloss: 0.0387417\tvalid_1's auc: 0.984776\tvalid_1's binary_logloss: 0.0430958\n",
      "Fold 32 AUC : 0.984776\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's auc: 0.989334\ttraining's binary_logloss: 0.0424286\tvalid_1's auc: 0.983282\tvalid_1's binary_logloss: 0.0502011\n",
      "Fold 33 AUC : 0.983282\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991965\ttraining's binary_logloss: 0.0368778\tvalid_1's auc: 0.983512\tvalid_1's binary_logloss: 0.0486977\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's auc: 0.991046\ttraining's binary_logloss: 0.0381514\tvalid_1's auc: 0.983629\tvalid_1's binary_logloss: 0.0485677\n",
      "Fold 34 AUC : 0.983629\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992064\ttraining's binary_logloss: 0.0372814\tvalid_1's auc: 0.98188\tvalid_1's binary_logloss: 0.0442489\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's auc: 0.993809\ttraining's binary_logloss: 0.034783\tvalid_1's auc: 0.982254\tvalid_1's binary_logloss: 0.043919\n",
      "Fold 35 AUC : 0.982254\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992005\ttraining's binary_logloss: 0.037164\tvalid_1's auc: 0.986637\tvalid_1's binary_logloss: 0.0443704\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's auc: 0.991749\ttraining's binary_logloss: 0.0375195\tvalid_1's auc: 0.986692\tvalid_1's binary_logloss: 0.0443515\n",
      "Fold 36 AUC : 0.986692\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992192\ttraining's binary_logloss: 0.036838\tvalid_1's auc: 0.981833\tvalid_1's binary_logloss: 0.0474783\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's auc: 0.991606\ttraining's binary_logloss: 0.0376352\tvalid_1's auc: 0.982028\tvalid_1's binary_logloss: 0.0473362\n",
      "Fold 37 AUC : 0.982028\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.99179\ttraining's binary_logloss: 0.0372905\tvalid_1's auc: 0.984353\tvalid_1's binary_logloss: 0.0469556\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's auc: 0.991295\ttraining's binary_logloss: 0.0379993\tvalid_1's auc: 0.984465\tvalid_1's binary_logloss: 0.0469201\n",
      "Fold 38 AUC : 0.984465\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991876\ttraining's binary_logloss: 0.0369883\tvalid_1's auc: 0.982946\tvalid_1's binary_logloss: 0.0484945\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's auc: 0.991139\ttraining's binary_logloss: 0.0380407\tvalid_1's auc: 0.983023\tvalid_1's binary_logloss: 0.0483609\n",
      "Fold 39 AUC : 0.983023\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's auc: 0.989246\ttraining's binary_logloss: 0.0416001\tvalid_1's auc: 0.986885\tvalid_1's binary_logloss: 0.0465249\n",
      "Fold 40 AUC : 0.986885\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992196\ttraining's binary_logloss: 0.036475\tvalid_1's auc: 0.982698\tvalid_1's binary_logloss: 0.0512534\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's auc: 0.990955\ttraining's binary_logloss: 0.0382177\tvalid_1's auc: 0.982679\tvalid_1's binary_logloss: 0.0511677\n",
      "Fold 41 AUC : 0.982679\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992162\ttraining's binary_logloss: 0.0367774\tvalid_1's auc: 0.985418\tvalid_1's binary_logloss: 0.0450847\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's auc: 0.990081\ttraining's binary_logloss: 0.0399264\tvalid_1's auc: 0.985774\tvalid_1's binary_logloss: 0.0451188\n",
      "Fold 42 AUC : 0.985774\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992127\ttraining's binary_logloss: 0.0369945\tvalid_1's auc: 0.982037\tvalid_1's binary_logloss: 0.0470884\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's auc: 0.990271\ttraining's binary_logloss: 0.0396748\tvalid_1's auc: 0.982298\tvalid_1's binary_logloss: 0.0467661\n",
      "Fold 43 AUC : 0.982298\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's auc: 0.989404\ttraining's binary_logloss: 0.0418962\tvalid_1's auc: 0.986501\tvalid_1's binary_logloss: 0.0449291\n",
      "Fold 44 AUC : 0.986501\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's auc: 0.989683\ttraining's binary_logloss: 0.0410297\tvalid_1's auc: 0.98103\tvalid_1's binary_logloss: 0.0497793\n",
      "Fold 45 AUC : 0.981030\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992075\ttraining's binary_logloss: 0.0367738\tvalid_1's auc: 0.982469\tvalid_1's binary_logloss: 0.0489575\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's auc: 0.990289\ttraining's binary_logloss: 0.0395429\tvalid_1's auc: 0.982632\tvalid_1's binary_logloss: 0.0488719\n",
      "Fold 46 AUC : 0.982632\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's auc: 0.989793\ttraining's binary_logloss: 0.0407636\tvalid_1's auc: 0.984372\tvalid_1's binary_logloss: 0.0448213\n",
      "Fold 47 AUC : 0.984372\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's auc: 0.989308\ttraining's binary_logloss: 0.0419363\tvalid_1's auc: 0.987678\tvalid_1's binary_logloss: 0.0447975\n",
      "Fold 48 AUC : 0.987678\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991925\ttraining's binary_logloss: 0.0372149\tvalid_1's auc: 0.985228\tvalid_1's binary_logloss: 0.0450754\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's auc: 0.990188\ttraining's binary_logloss: 0.0397247\tvalid_1's auc: 0.985523\tvalid_1's binary_logloss: 0.0448512\n",
      "Fold 49 AUC : 0.985523\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991811\ttraining's binary_logloss: 0.0369269\tvalid_1's auc: 0.984389\tvalid_1's binary_logloss: 0.0507263\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's auc: 0.990611\ttraining's binary_logloss: 0.0386593\tvalid_1's auc: 0.984705\tvalid_1's binary_logloss: 0.0505982\n",
      "Fold 50 AUC : 0.984705\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992051\ttraining's binary_logloss: 0.0367443\tvalid_1's auc: 0.981954\tvalid_1's binary_logloss: 0.0495819\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's auc: 0.990036\ttraining's binary_logloss: 0.0399746\tvalid_1's auc: 0.982329\tvalid_1's binary_logloss: 0.0494252\n",
      "Fold 51 AUC : 0.982329\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.991979\ttraining's binary_logloss: 0.0370527\tvalid_1's auc: 0.984935\tvalid_1's binary_logloss: 0.0471537\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's auc: 0.991043\ttraining's binary_logloss: 0.0383753\tvalid_1's auc: 0.985118\tvalid_1's binary_logloss: 0.0469858\n",
      "Fold 52 AUC : 0.985118\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992379\ttraining's binary_logloss: 0.0363248\tvalid_1's auc: 0.982362\tvalid_1's binary_logloss: 0.0489174\n",
      "Early stopping, best iteration is:\n",
      "[115]\ttraining's auc: 0.993108\ttraining's binary_logloss: 0.0352864\tvalid_1's auc: 0.982379\tvalid_1's binary_logloss: 0.0488914\n",
      "Fold 53 AUC : 0.982379\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992146\ttraining's binary_logloss: 0.0370118\tvalid_1's auc: 0.982579\tvalid_1's binary_logloss: 0.0450058\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's auc: 0.990369\ttraining's binary_logloss: 0.0397685\tvalid_1's auc: 0.983097\tvalid_1's binary_logloss: 0.0446276\n",
      "Fold 54 AUC : 0.983097\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.99297\ttraining's binary_logloss: 0.0355089\tvalid_1's auc: 0.981851\tvalid_1's binary_logloss: 0.0535764\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's auc: 0.99049\ttraining's binary_logloss: 0.0390996\tvalid_1's auc: 0.982195\tvalid_1's binary_logloss: 0.0533342\n",
      "Fold 55 AUC : 0.982195\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992068\ttraining's binary_logloss: 0.0366094\tvalid_1's auc: 0.984963\tvalid_1's binary_logloss: 0.0501376\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's auc: 0.990086\ttraining's binary_logloss: 0.0394741\tvalid_1's auc: 0.985319\tvalid_1's binary_logloss: 0.0498484\n",
      "Fold 56 AUC : 0.985319\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's auc: 0.989441\ttraining's binary_logloss: 0.0414509\tvalid_1's auc: 0.983475\tvalid_1's binary_logloss: 0.0497347\n",
      "Fold 57 AUC : 0.983475\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.988836\ttraining's binary_logloss: 0.0447435\tvalid_1's auc: 0.984589\tvalid_1's binary_logloss: 0.0524257\n",
      "Fold 58 AUC : 0.984589\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.988475\ttraining's binary_logloss: 0.0489386\tvalid_1's auc: 0.984184\tvalid_1's binary_logloss: 0.0530772\n",
      "Fold 59 AUC : 0.984184\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's auc: 0.989454\ttraining's binary_logloss: 0.042098\tvalid_1's auc: 0.984039\tvalid_1's binary_logloss: 0.0461963\n",
      "Fold 60 AUC : 0.984039\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992227\ttraining's binary_logloss: 0.0369214\tvalid_1's auc: 0.980072\tvalid_1's binary_logloss: 0.0471493\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's auc: 0.990686\ttraining's binary_logloss: 0.0391635\tvalid_1's auc: 0.980323\tvalid_1's binary_logloss: 0.0467899\n",
      "Fold 61 AUC : 0.980323\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992019\ttraining's binary_logloss: 0.0370121\tvalid_1's auc: 0.984488\tvalid_1's binary_logloss: 0.0462283\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's auc: 0.990812\ttraining's binary_logloss: 0.0387042\tvalid_1's auc: 0.984764\tvalid_1's binary_logloss: 0.0459936\n",
      "Fold 62 AUC : 0.984764\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992381\ttraining's binary_logloss: 0.0363016\tvalid_1's auc: 0.984985\tvalid_1's binary_logloss: 0.049241\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's auc: 0.991296\ttraining's binary_logloss: 0.0378531\tvalid_1's auc: 0.985193\tvalid_1's binary_logloss: 0.0491649\n",
      "Fold 63 AUC : 0.985193\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992297\ttraining's binary_logloss: 0.0365498\tvalid_1's auc: 0.983249\tvalid_1's binary_logloss: 0.0487286\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's auc: 0.990156\ttraining's binary_logloss: 0.0398699\tvalid_1's auc: 0.983731\tvalid_1's binary_logloss: 0.048139\n",
      "Fold 64 AUC : 0.983731\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992583\ttraining's binary_logloss: 0.0361931\tvalid_1's auc: 0.982243\tvalid_1's binary_logloss: 0.0496626\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's auc: 0.99132\ttraining's binary_logloss: 0.0380396\tvalid_1's auc: 0.982427\tvalid_1's binary_logloss: 0.0492261\n",
      "Fold 65 AUC : 0.982427\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992219\ttraining's binary_logloss: 0.036788\tvalid_1's auc: 0.983491\tvalid_1's binary_logloss: 0.0476116\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's auc: 0.99017\ttraining's binary_logloss: 0.0397467\tvalid_1's auc: 0.984411\tvalid_1's binary_logloss: 0.0470351\n",
      "Fold 66 AUC : 0.984411\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991699\ttraining's binary_logloss: 0.0375098\tvalid_1's auc: 0.986286\tvalid_1's binary_logloss: 0.0443339\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's auc: 0.990882\ttraining's binary_logloss: 0.0385934\tvalid_1's auc: 0.986447\tvalid_1's binary_logloss: 0.0441568\n",
      "Fold 67 AUC : 0.986447\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991918\ttraining's binary_logloss: 0.0371899\tvalid_1's auc: 0.984973\tvalid_1's binary_logloss: 0.0445529\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's auc: 0.989746\ttraining's binary_logloss: 0.0403133\tvalid_1's auc: 0.985414\tvalid_1's binary_logloss: 0.0442722\n",
      "Fold 68 AUC : 0.985414\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.99202\ttraining's binary_logloss: 0.0369602\tvalid_1's auc: 0.985648\tvalid_1's binary_logloss: 0.0467169\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's auc: 0.989933\ttraining's binary_logloss: 0.039988\tvalid_1's auc: 0.985801\tvalid_1's binary_logloss: 0.0467307\n",
      "Fold 69 AUC : 0.985801\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's auc: 0.989001\ttraining's binary_logloss: 0.0445901\tvalid_1's auc: 0.984594\tvalid_1's binary_logloss: 0.0442333\n",
      "Fold 70 AUC : 0.984594\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's auc: 0.988839\ttraining's binary_logloss: 0.0436664\tvalid_1's auc: 0.985248\tvalid_1's binary_logloss: 0.0454928\n",
      "Fold 71 AUC : 0.985248\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.99188\ttraining's binary_logloss: 0.0373712\tvalid_1's auc: 0.985767\tvalid_1's binary_logloss: 0.0435301\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's auc: 0.989586\ttraining's binary_logloss: 0.0409746\tvalid_1's auc: 0.986321\tvalid_1's binary_logloss: 0.0437194\n",
      "Fold 72 AUC : 0.986321\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992145\ttraining's binary_logloss: 0.0370907\tvalid_1's auc: 0.982716\tvalid_1's binary_logloss: 0.045015\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's auc: 0.990859\ttraining's binary_logloss: 0.0388861\tvalid_1's auc: 0.98313\tvalid_1's binary_logloss: 0.0447344\n",
      "Fold 73 AUC : 0.983130\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.99209\ttraining's binary_logloss: 0.0371551\tvalid_1's auc: 0.98428\tvalid_1's binary_logloss: 0.044695\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's auc: 0.992642\ttraining's binary_logloss: 0.0364395\tvalid_1's auc: 0.984365\tvalid_1's binary_logloss: 0.0446027\n",
      "Fold 74 AUC : 0.984365\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992293\ttraining's binary_logloss: 0.0368016\tvalid_1's auc: 0.983974\tvalid_1's binary_logloss: 0.0456896\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's auc: 0.990439\ttraining's binary_logloss: 0.0394406\tvalid_1's auc: 0.984301\tvalid_1's binary_logloss: 0.0453916\n",
      "Fold 75 AUC : 0.984301\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.988759\ttraining's binary_logloss: 0.0448659\tvalid_1's auc: 0.984377\tvalid_1's binary_logloss: 0.0492425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 76 AUC : 0.984377\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.99216\ttraining's binary_logloss: 0.0368978\tvalid_1's auc: 0.985639\tvalid_1's binary_logloss: 0.0449414\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's auc: 0.991649\ttraining's binary_logloss: 0.0376324\tvalid_1's auc: 0.985793\tvalid_1's binary_logloss: 0.0448942\n",
      "Fold 77 AUC : 0.985793\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992216\ttraining's binary_logloss: 0.0368424\tvalid_1's auc: 0.982624\tvalid_1's binary_logloss: 0.0488734\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's auc: 0.991085\ttraining's binary_logloss: 0.038342\tvalid_1's auc: 0.98288\tvalid_1's binary_logloss: 0.0486078\n",
      "Fold 78 AUC : 0.982880\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.988703\ttraining's binary_logloss: 0.0456701\tvalid_1's auc: 0.984235\tvalid_1's binary_logloss: 0.0485459\n",
      "Fold 79 AUC : 0.984235\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.988866\ttraining's binary_logloss: 0.0439102\tvalid_1's auc: 0.986533\tvalid_1's binary_logloss: 0.0466306\n",
      "Fold 80 AUC : 0.986533\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992083\ttraining's binary_logloss: 0.0370316\tvalid_1's auc: 0.984851\tvalid_1's binary_logloss: 0.0446154\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's auc: 0.990034\ttraining's binary_logloss: 0.0399145\tvalid_1's auc: 0.985006\tvalid_1's binary_logloss: 0.0446805\n",
      "Fold 81 AUC : 0.985006\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991955\ttraining's binary_logloss: 0.0371287\tvalid_1's auc: 0.985081\tvalid_1's binary_logloss: 0.0458311\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's auc: 0.990467\ttraining's binary_logloss: 0.0392645\tvalid_1's auc: 0.985594\tvalid_1's binary_logloss: 0.0454515\n",
      "Fold 82 AUC : 0.985594\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992112\ttraining's binary_logloss: 0.0367162\tvalid_1's auc: 0.98361\tvalid_1's binary_logloss: 0.0492584\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's auc: 0.990146\ttraining's binary_logloss: 0.039622\tvalid_1's auc: 0.983653\tvalid_1's binary_logloss: 0.0491504\n",
      "Fold 83 AUC : 0.983653\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's auc: 0.989237\ttraining's binary_logloss: 0.0426693\tvalid_1's auc: 0.986013\tvalid_1's binary_logloss: 0.0448509\n",
      "Fold 84 AUC : 0.986013\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991964\ttraining's binary_logloss: 0.0371216\tvalid_1's auc: 0.985306\tvalid_1's binary_logloss: 0.0450213\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's auc: 0.990449\ttraining's binary_logloss: 0.0393142\tvalid_1's auc: 0.985433\tvalid_1's binary_logloss: 0.044989\n",
      "Fold 85 AUC : 0.985433\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991999\ttraining's binary_logloss: 0.0369911\tvalid_1's auc: 0.983892\tvalid_1's binary_logloss: 0.046864\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's auc: 0.990565\ttraining's binary_logloss: 0.0391093\tvalid_1's auc: 0.984079\tvalid_1's binary_logloss: 0.046669\n",
      "Fold 86 AUC : 0.984079\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.989553\ttraining's binary_logloss: 0.0413042\tvalid_1's auc: 0.986437\tvalid_1's binary_logloss: 0.0454856\n",
      "Fold 87 AUC : 0.986437\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992286\ttraining's binary_logloss: 0.0367196\tvalid_1's auc: 0.983157\tvalid_1's binary_logloss: 0.0475682\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's auc: 0.991793\ttraining's binary_logloss: 0.0374399\tvalid_1's auc: 0.983206\tvalid_1's binary_logloss: 0.0474631\n",
      "Fold 88 AUC : 0.983206\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992182\ttraining's binary_logloss: 0.0369758\tvalid_1's auc: 0.984192\tvalid_1's binary_logloss: 0.0439405\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's auc: 0.991721\ttraining's binary_logloss: 0.0376397\tvalid_1's auc: 0.9843\tvalid_1's binary_logloss: 0.0438573\n",
      "Fold 89 AUC : 0.984300\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's auc: 0.988807\ttraining's binary_logloss: 0.0432289\tvalid_1's auc: 0.986725\tvalid_1's binary_logloss: 0.0473033\n",
      "Fold 90 AUC : 0.986725\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.988922\ttraining's binary_logloss: 0.0439281\tvalid_1's auc: 0.985909\tvalid_1's binary_logloss: 0.0471651\n",
      "Fold 91 AUC : 0.985909\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's auc: 0.989147\ttraining's binary_logloss: 0.0430827\tvalid_1's auc: 0.987686\tvalid_1's binary_logloss: 0.0423489\n",
      "Fold 92 AUC : 0.987686\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's auc: 0.989502\ttraining's binary_logloss: 0.0416838\tvalid_1's auc: 0.982989\tvalid_1's binary_logloss: 0.0494579\n",
      "Fold 93 AUC : 0.982989\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's auc: 0.989055\ttraining's binary_logloss: 0.0425558\tvalid_1's auc: 0.984782\tvalid_1's binary_logloss: 0.0472777\n",
      "Fold 94 AUC : 0.984782\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992208\ttraining's binary_logloss: 0.0367036\tvalid_1's auc: 0.981758\tvalid_1's binary_logloss: 0.0491071\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's auc: 0.991445\ttraining's binary_logloss: 0.0378346\tvalid_1's auc: 0.982058\tvalid_1's binary_logloss: 0.0487457\n",
      "Fold 95 AUC : 0.982058\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991771\ttraining's binary_logloss: 0.0372406\tvalid_1's auc: 0.984608\tvalid_1's binary_logloss: 0.0467527\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's auc: 0.993934\ttraining's binary_logloss: 0.0341552\tvalid_1's auc: 0.984735\tvalid_1's binary_logloss: 0.0466014\n",
      "Fold 96 AUC : 0.984735\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's auc: 0.98977\ttraining's binary_logloss: 0.0410185\tvalid_1's auc: 0.98232\tvalid_1's binary_logloss: 0.0473168\n",
      "Fold 97 AUC : 0.982320\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's auc: 0.98974\ttraining's binary_logloss: 0.041122\tvalid_1's auc: 0.982949\tvalid_1's binary_logloss: 0.0500953\n",
      "Fold 98 AUC : 0.982949\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.991928\ttraining's binary_logloss: 0.0371133\tvalid_1's auc: 0.984988\tvalid_1's binary_logloss: 0.0460557\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's auc: 0.989651\ttraining's binary_logloss: 0.0407266\tvalid_1's auc: 0.985372\tvalid_1's binary_logloss: 0.0462539\n",
      "Fold 99 AUC : 0.985372\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's auc: 0.992176\ttraining's binary_logloss: 0.0368888\tvalid_1's auc: 0.980316\tvalid_1's binary_logloss: 0.0481848\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's auc: 0.99014\ttraining's binary_logloss: 0.0398323\tvalid_1's auc: 0.980794\tvalid_1's binary_logloss: 0.0476038\n",
      "Fold 100 AUC : 0.980794\n",
      "Full AUC score 0.984346\n"
     ]
    }
   ],
   "source": [
    "del data\n",
    "del train_data,test_public\n",
    "\n",
    "\n",
    "y = train['isDefault']\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=546789)\n",
    "oof_preds, test_preds, importances = train_model(train, test, y, folds)\n",
    "test_preds.rename({'loan_id': 'id'}, axis=1)[['id', 'isDefault']].to_csv('./submit/test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35d7260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>isDefault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12022</th>\n",
       "      <td>1000575</td>\n",
       "      <td>0.137611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12023</th>\n",
       "      <td>1028125</td>\n",
       "      <td>1.150230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12024</th>\n",
       "      <td>1010694</td>\n",
       "      <td>0.095758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12025</th>\n",
       "      <td>1026712</td>\n",
       "      <td>0.103049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12026</th>\n",
       "      <td>1002895</td>\n",
       "      <td>0.091717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17017</th>\n",
       "      <td>1008856</td>\n",
       "      <td>7.356238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17018</th>\n",
       "      <td>1016651</td>\n",
       "      <td>0.173695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17019</th>\n",
       "      <td>1024140</td>\n",
       "      <td>0.061422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17020</th>\n",
       "      <td>1014316</td>\n",
       "      <td>0.114910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17021</th>\n",
       "      <td>1012946</td>\n",
       "      <td>0.066775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_id  isDefault\n",
       "12022  1000575   0.137611\n",
       "12023  1028125   1.150230\n",
       "12024  1010694   0.095758\n",
       "12025  1026712   0.103049\n",
       "12026  1002895   0.091717\n",
       "...        ...        ...\n",
       "17017  1008856   7.356238\n",
       "17018  1016651   0.173695\n",
       "17019  1024140   0.061422\n",
       "17020  1014316   0.114910\n",
       "17021  1012946   0.066775\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129085fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
